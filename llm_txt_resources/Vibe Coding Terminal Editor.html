<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Vibe Coding Terminal Editor</title>
    <meta
      name="description"
      content="I wrote a small tool for myself as my biannual
routine check of where llms are currently at. I think I&#039;ve learned a bunch from this exercise. This
is frustrating! I don&#039;t want to learn by trial and error, I&#039;d rather read someone&#039;s blog post with
lessons learned. Sadly, most of the writing on the topic that percolates to me tends to be
high-level --- easy to nod along while reading, but hard to extract actionable lessons. So this is
what I want to do here, list specific tricks learned."
    >
    <link rel="icon" href="/favicon.png" type="image/png">
    <link rel="icon" href="/favicon.svg" type="image/svg+xml">
    <link
      rel="canonical"
      href="https://matklad.github.io/2025/08/31/vibe-coding-terminal-editor.html"
    >
    <link
      rel="alternate"
      type="application/rss+xml"
      title="matklad"
      href="https://matklad.github.io/feed.xml"
    >
    <style>
      @font-face {
        font-family: "Open Sans";
        src: url("/css/OpenSans-300-Normal.woff2") format("woff2");
        font-weight: 300;
        font-style: normal;
      }
      @font-face {
        font-family: "JetBrains Mono";
        src: url("/css/JetBrainsMono-400-Normal.woff2") format("woff2");
        font-weight: 400;
        font-style: normal;
      }
      @font-face {
        font-family: "JetBrains Mono";
        src: url("/css/JetBrainsMono-700-Normal.woff2") format("woff2");
        font-weight: 700;
        font-style: normal;
      }
      @font-face {
        font-family: "EB Garamond";
        src: url("/css/EBGaramond-400-Normal.woff2") format("woff2");
        font-weight: 400;
        font-style: normal;
      }
      @font-face {
        font-family: "EB Garamond";
        src: url("/css/EBGaramond-400-Italic.woff2") format("woff2");
        font-weight: 400;
        font-style: italic;
      }
      @font-face {
        font-family: "EB Garamond";
        src: url("/css/EBGaramond-700-Normal.woff2") format("woff2");
        font-weight: 700;
        font-style: normal;
      }
      @font-face {
        font-family: "EB Garamond";
        src: url("/css/EBGaramond-700-Italic.woff2") format("woff2");
        font-weight: 700;
        font-style: italic;
      }
    </style>
    <link rel="stylesheet" href="/css/main.css">
  </head>
  <body>
    <header>
      <nav>
        <a class="title" href="/">matklad</a><a href="/about.html">About</a><a
          href="/links.html"
        >Links</a><a href="/blogroll.html">Blogroll</a>
      </nav>
    </header>
    <main>
      <article>
        <header>
          <h1>Vibe Coding Terminal Editor</h1>
          <time class="meta" datetime="2025-08-31">Aug 31, 2025</time>
        </header>
        <p>
          I “wrote” <a href="https://github.com/matklad/terminal-editor/"
          >a small tool</a> for myself as my biannual routine check of where
          llms are currently at. I think I’ve learned a bunch from this
          exercise. This is frustrating! I don’t want to learn by trial and
          error, I’d rather read someone’s blog post with lessons learned.
          Sadly, <em>most</em> of the writing on the topic that percolates to me
          tends to be high-level — easy to nod along while reading, but hard to
          extract actionable lessons. So this is what I want to do here, list
          specific tricks learned.
        </p>
        <section id="Terminal-Editor">
          <h2><a href="#Terminal-Editor">Terminal Editor</a></h2>
          <p>
            Let me quickly introduce the project. It’s a VS Code extension that
            allows me to run “shell” inside my normal editor widget, such that
            the output is normal text buffer where all standard motion/editing
            commands work. So I can “goto definition” on paths printed as a part
            of backtrace, use multiple cursors to copy compiler’s suggestions,
            or just <kbd><kbd>PageUp</kbd></kbd> / <kbd><kbd
              >PageDown</kbd></kbd> to scroll the output. If you are familiar
            with Emacs, it’s
            <a
              href="https://www.gnu.org/software/emacs/manual/html_mono/eshell.html"
            >Eshell</a>, just worse:
          </p>

          <figure>
            <img
              alt=""
              src="https://github.com/user-attachments/assets/acaf653e-a170-4685-8cce-5ca8dd31b9b4"
              width="1398"
              height="1086"
            >
          </figure>
          <p>
            I now use <code>terminal-editor</code> to launch most of my
            compilation commands, as it has several niceties on top of what my
            normal shell provides. For example, by default only the last 50
            lines of output are shown, but I can hit tab to fold and unfold full
            output. Such a simple feature, but such a pain to implement in a
            UNIX shell/terminal!
          </p>
          <p>What follows is an unstructured bag of things learned:</p>
        </section>
        <section id="Plan-Reset">
          <h2><a href="#Plan-Reset">Plan / Reset</a></h2>
          <p>
            I originally tried to use <code>claude</code> code normally, by
            iteratively prompting in the terminal until I get the output I want.
            This was frustrating, as it was too easy to miss a good place to
            commit a chunk of work, or to rein in a conversation going astray.
            This “prompting-then-waiting” mode also had a pattern of mental
            context switches not matching my preferred style of work. This
            article suggests a better workflow: <a
              href="https://harper.blog/2025/05/08/basic-claude-code/"
              class="display url"
            >https://harper.blog/2025/05/08/basic-claude-code/</a>
          </p>
          <p>
            Instead of writing your single prompt in the terminal, you write an
            entire course of action as a task list in <code>plan.md</code>
            document, and the actual prompt is then something along the lines of
          </p>

          <figure class="blockquote">
            <blockquote>
              <p>
                Read @plan.md, complete the next task, and mark it with <code
                >X</code>.
              </p>
            </blockquote>
          </figure>
          <p>
            After <code>claude</code> finishes iterating on a step you look at
            the diff and interactively prompt for necessary corrections. When
            you are happy, <code>git commit</code> and <code>/clear</code> the
            conversation, to start the next step from the clean slate.
          </p>
          <p>
            The plan pattern reduces context switches, because it allows you to
            plan several steps ahead, while you are in the planning mode, even
            if it makes sense to do the work one step at a time. I often also
            work on continuing the plan when <code>claude</code> is working on
            the current task.
          </p>
        </section>
        <section id="Whiteboard-Agent-Metaphor">
          <h2>
            <a href="#Whiteboard-Agent-Metaphor">Whiteboard / Agent Metaphor</a>
          </h2>
          <p>
            A brilliant metaphor from another post
            <a
              href="https://crawshaw.io/blog/programming-with-agents"
              class="display url"
            >https://crawshaw.io/blog/programming-with-agents</a>
            is that prompting LLM for some coding task and then expecting it to
            one-shot a working solution is quite a bit like asking a candidate
            to whiteboard an algorithm during the interview.
          </p>
          <p>
            LLMs are clearly superhuman at whiteboarding, but you can’t go far
            without feedback. “Agentic” programming like <code>claude</code>
            allows LLMs to iterate on solution.
          </p>
          <p>
            LLMs are <em>much</em> better at whiteboarding than at iterating. My
            experience is that, starting with suboptimal solution, LLM generally
            can’t improve it by itself along the fuzzy aesthetic metrics I care
            about. They can make valid changes, but the overall quality stays
            roughly the same.
          </p>
          <p>
            However, LLMs are tenacious, and can do a lot of iterations. If you
            <em>do</em> have a value function, you can use it to extract useful
            work from random walk! A <em>bad</em> value function is human
            judgement. Sitting in the loop with LLM and pointing out mistakes is
            both frustrating and slow (you are the bottleneck). In contrast
            “make this test green” is very efficient at getting working (≠ good)
            code.
          </p>
        </section>
        <section id="Spec-Is-Code-Is-Tests">
          <h2><a href="#Spec-Is-Code-Is-Tests">Spec Is Code Is Tests</a></h2>
          <p>
            LLMs are good at “closing the loop”, they can make the ends meet.
            This insight combined with the
            <code>plan.md</code> pattern gives my current workflow — spec ↔ code
            ↔ test loop. Here’s the story:
          </p>
          <p>
            I coded the first version of <code>terminal-editor</code> using just
            the <code>plan.md</code> pattern, but at some point I hit complexity
            wall. I realized that my original implementation strategy for syntax
            highlighting was a dead end, and I needed to change it, but that was
            hard to do without making a complete mess of the code. The
            accumulated <code>plan.md</code> reflected a bunch of historical
            detours, and the tests were too brittle and coupled to the existing
            implementation (more on tests later). This worked for incremental
            additions, but now I wanted to change something in the middle.
          </p>
          <p>
            I realized that what I want is not an append-only <code
            >plan.md</code> that reflects history, but rather a mutable <code
            >spec.md</code> that describes clearly how the software should
            behave. For normal engineering, this would have been “damn, I guess
            I need to throw one out and start afresh” moment. With <code
            >claude</code>, I added <code>plan.md</code> and all the code to the
            context and asked it to write <code>spec.md</code> file in the same
            task list format. There are two insights here:
          </p>
          <p>
            <em>First</em>, mutable spec is a good way to instruct LLM. When I
            want to apply a change to
            <code>terminal-editor</code> now, I prompt <code>claude</code> to
            update the spec first (unchecking any items that need re-doing),
            manually review/touch-up the spec, and use a canned prompt to align
            the code and tests with the spec.
          </p>
          <p>
            <em>Second</em>, that you can think of an LLM as a machine
            translation, which can automatically convert between working code,
            specification, and tests. You can treat <em>any</em> of those things
            as an input, as if you are coding in <a
              href="https://minikanren.org"
            >miniKanren</a>!
          </p>
        </section>
        <section id="Tests">
          <h2><a href="#Tests">Tests</a></h2>
          <p>
            I did have this idea of closing the loop when I started with <code
            >terminal-editor</code>, so I crafted the prompts to emphasize
            testing. You can guess the result! <code>claude</code> wrote a lot
            of tests, following all the modern “best practices” — a deluge of
            unit tests that were just needlessly nailing down internal API, a
            jungle of bug-hiding mocks, and a bunch of unfocused integration
            tests which were slow, flaky, and contained a copious amount of
            sleeps to paper over synchronization bugs. Really, this was eerily
            similar to a typical test suite you can find in the wild. I am
            wondering why is that?
          </p>
          <p>
            This is perhaps my main take away: if I am vibe-coding anything
            again, and I want to maintain it and not just one-shot it, I will
            think very hard about the testing strategy. Really, to tout my own
            horn, I think that perhaps <a
              href="https://matklad.github.io/2021/05/31/how-to-test.html"
            ><em>How to Test?</em></a>
            is the best article out there about agentic coding. Test iteration
            is a multiplier for humans, but a hard requirement for LLMs. Test
            must be very fast, non-flaky, and should end-to-end test application
            <em>features</em>, rather than code.
          </p>
          <p>
            Concretely, I just completely wiped out all the existing tests. Then
            I added testing strategy to the spec. There are two functions:
          </p>

          <figure class="code-block">
            <pre>
<code><span class="line"><span class="hl-keyword">export</span> <span class="hl-keyword">async</span> <span class="hl-keyword">function</span> <span class="hl-title function_">sync</span>(<span class="hl-params"></span>): <span class="hl-title class_">Promise</span>&lt;<span class="hl-built_in">void</span>&gt;</span>
<span class="line"><span class="hl-keyword">export</span> <span class="hl-keyword">function</span> <span class="hl-title function_">snapshot</span>(<span class="hl-params"></span>): <span class="hl-built_in">string</span></span></code></pre>
          </figure>
          <p>
            The <code>sync</code> function waits for all outstanding async work
            (like external processes) to finish. This requires properly
            threading causality throughout the code. E.g., there’s a promise you
            can <code>await</code>
            on to join currently running process. The <code>snapshot</code>
            function captures the entire state of the extension as a single
            string. There’s just one mock for the clock (another improvement on
            the usual terminal — process runtime is always show).
          </p>
          <p>
            Then, I prompted <code>claude</code> with something along the lines
            of
          </p>

          <figure class="blockquote">
            <blockquote>
              <p>
                Oups, looks like someone wiped out all the tests here, but the
                code and the spec look decent, could you re-create the test
                suite using <code>snapshot</code> function as per @spec.md?
              </p>
            </blockquote>
          </figure>
          <p>It worked. Again, “throw one away” is very cheap.</p>
        </section>
        <section id="Conclusions">
          <h2><a href="#Conclusions">Conclusions</a></h2>
          <p>
            That’s it! LLMs obviously can code. You need to hold them right. In
            particular, you need to engineer a feedback loop to let LLM iterate
            at its own pace. You don’t want human in the “data plane” of the
            loop, only in the control plane. Learn to <a
              href="https://matklad.github.io/2021/05/31/how-to-test.html"
            >architecture for testing</a>.
          </p>
          <p>
            LLM drastically reduce the activation energy for writing custom
            tools. I wanted something like
            <code>terminal-editor</code> forever, but it was never the most
            attractive yak to shave. Well, now I have the thing, I use it daily.
          </p>
          <p>
            LLMs don’t magically solve all software engineering problems. The
            biggest time sink with
            <code>terminal-editor</code> was solving the <code>pty</code>
            problem, but LLMs are not yet at the “give me UNIX, but without
            <code>pty</code> mess” stage.
          </p>
          <p>
            LLMs don’t solve maintenance. A while ago I wrote about
            <a href="https://matklad.github.io/2024/12/13/majjit-lsp.html"><em
              >LSP for jj</em></a>. I think I can actually code that up in a day
            with Claude now? Not the proof of concept, the production version
            with everything
            <em>I</em> would need. But I don’t want to <em>maintain</em> that. I
            don’t want to context switch to fix a minor bug, if I am the only
            one using the tool. And, well, if I make this for other people, I’d
            definitely be on the hook for maintaining it :D
          </p>
        </section>
      </article>
    </main>
    <footer>
      <p>
        <a
          href="https://github.com/matklad/matklad.github.io/edit/master/content/posts/2025-08-31-vibe-coding-terminal-editor.dj"
        ><svg><use href="/assets/icons.svg#edit" /></svg>Fix typo</a><a
          href="/feed.xml"
        ><svg><use href="/assets/icons.svg#rss" /></svg>Subscribe</a><a
          href="mailto:aleksey.kladov+blog@gmail.com"
        ><svg><use href="/assets/icons.svg#email" /></svg>Get in touch</a><a
          href="https://github.com/matklad"
        ><svg><use href="/assets/icons.svg#github" /></svg>matklad</a>
      </p>
    </footer>
  </body>
</html>
